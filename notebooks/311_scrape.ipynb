{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_addr(add):\n",
    "    add = add.replace('    ', ' ') # 4 space\n",
    "    add = add.replace('   ', ' ') # 3 space\n",
    "    add = add.replace('  ', ' ') # 2 space\n",
    "    add = add.replace(' - ', '-') # spaces around dash\n",
    "    add = add.upper()\n",
    "    add = add.replace(' AVE,', ' AVENUE,')\n",
    "    add = add.replace(' AVE ', ' AVENUE ')\n",
    "    add = add.replace(' AV,', ' AVENUE,') \n",
    "    add = add.replace(' AV ', ' AVENUE ')\n",
    "    add = add.replace(' ST,', ' STREET,')\n",
    "    add = add.replace(' ST ', ' STREET ')\n",
    "    add = add.replace(' PL,', ' PLACE,')\n",
    "    add = add.replace(' PL ', ' PLACE ')\n",
    "    add = add.replace(' RD,', ' ROAD,')\n",
    "    add = add.replace(' RD ', ' ROAD ')\n",
    "    add = add.replace(' BLVD,', ' BOULEVARD,')\n",
    "    add = add.replace(' BLVD ', ' BOULEVARD ')\n",
    "    add = add.replace('FIRST', '1')\n",
    "    add = add.replace('1ST', '1')\n",
    "    add = add.replace('SECOND', '2')\n",
    "    add = add.replace('2ND', '1')\n",
    "    add = add.replace('THIRD', '3')\n",
    "    add = add.replace('3RD', '3')\n",
    "    add = add.replace('FOURTH', '4')\n",
    "    add = add.replace('4TH', '4')\n",
    "    add = add.replace('FIFTH', '5')\n",
    "    add = add.replace('5TH', '5')\n",
    "    add = add.replace('SIXTH', '6')\n",
    "    add = add.replace('6TH', '6')\n",
    "    add = add.replace('SEVENTH', '7')\n",
    "    add = add.replace('7TH', '7')\n",
    "    add = add.replace('EIGHTH', '8')\n",
    "    add = add.replace('8TH', '8')\n",
    "    add = add.replace('NINTH', '9')\n",
    "    add = add.replace('9TH', '9')\n",
    "    add = add.replace(' E ', ' EAST ')\n",
    "    add = add.replace(' E,', ' EAST,')\n",
    "    add = add.replace(' W ', ' WEST ')\n",
    "    add = add.replace(' W,', ' WEST,')\n",
    "    add = add.replace(' N ', ' NORTH ')\n",
    "    add = add.replace(' N,', ' NORTH,')\n",
    "    add = add.replace(' S ', ' SOUTH ')\n",
    "    add = add.replace(' S,', ' SOUTH,')\n",
    "    return add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complaints = ['Food%20Poisoning',\n",
    "              'Food%20Establishment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complaint: Food%20Poisoning, offset: 0\n",
      "complaint: Food%20Establishment, offset: 0\n"
     ]
    }
   ],
   "source": [
    "# get food-related complaints from NYC 311 API\n",
    "df_311 = pd.DataFrame()\n",
    "for complaint in complaints:\n",
    "    \n",
    "    complaint = complaint\n",
    "    limit = 50000\n",
    "    # page through API results (max 50,000)\n",
    "    offset = 0\n",
    "    # any complaint opened after the start of 2012\n",
    "    start_date = \"2012-01-01T00:00:00.000\"\n",
    "    \n",
    "    while True:\n",
    "        query_string = \"\".join(\n",
    "        \"\"\"https://data.cityofnewyork.us/resource/fhrw-4uyv.json?\n",
    "        complaint_type={}&$\n",
    "        limit={}&$\n",
    "        offset={}&$\n",
    "        order=:id&$\n",
    "        where=created_date>'{}'\"\"\"\\\n",
    "        .format(complaint, limit, offset, start_date).splitlines()).replace(\"    \", \"\")\n",
    "        print 'complaint: {}, offset: {}'.format(complaint, offset)\n",
    "        \n",
    "        data = pd.read_json(query_string)\n",
    "        df_311 = df_311.append(data)\n",
    "\n",
    "        offset += 1\n",
    "        # if ever a response comes back with less than maximum data, last page has been reached\n",
    "        if len(data) < limit:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cleaning 311\n",
    "# incidents with real addresses only\n",
    "df_311 = df_311[df_311.address_type=='ADDRESS']\n",
    "# exclude missing addresses\n",
    "df_311 = df_311[map(lambda x: type(x)!=float, df_311['incident_address'])]\n",
    "# restaurant locations only\n",
    "df_311 = df_311[map(lambda typ: typ in ['Restaurant/Bar/Deli/Bakery', 'Soup Kitchen'], df_311.location_type)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_311.drop([u'address_type', u'agency', u'agency_name', \n",
    "       u'closed_date', u'community_board', u'created_date',\n",
    "       u'cross_street_1', u'cross_street_2', u'due_date',\n",
    "       u'intersection_street_1', u'intersection_street_2', u'landmark',\n",
    "       u'park_borough', u'park_facility_name',\n",
    "       u'resolution_action_updated_date', u'resolution_description',\n",
    "       u'school_address', u'school_city', u'school_code', u'school_name',\n",
    "       u'school_not_found', u'school_number', u'school_phone_number',\n",
    "       u'school_region', u'school_state', u'school_zip', u'status',\n",
    "       u'street_name', u'unique_key', u'x_coordinate_state_plane',\n",
    "       u'y_coordinate_state_plane'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_addr(row):\n",
    "    \"\"\"\n",
    "    combine address, borough, and zip, into a single string address\n",
    "    \"\"\"\n",
    "    return ', '.join([str(row['incident_address']),\n",
    "                      str(row['borough']),\n",
    "                      str(row['incident_zip'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_311.loc[:, 'addr'] = df_311.apply(combine_addr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# STANDARDIZE the 311 addresses in preparation for merging\n",
    "df_311.loc[:, 'addr'] = map(clean_addr, df_311.loc[:, 'addr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_311 = pd.DataFrame(df_311.groupby('addr').count().loc[:, 'descriptor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get original inspection data, with addresses\n",
    "insp = pd.read_csv('data/spatial_merged_3_fs_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exclude missing inspectionaddresses\n",
    "insp = insp[map(lambda x: type(x)!=float, insp['loc'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# STANDARDIZE the 311 addresses in preparation for merging\n",
    "insp.loc[:, 'loc'] = map(clean_addr, insp.loc[:, 'loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "addr\n",
       "1 8 AVENUE, BROOKLYN, 11217                   1\n",
       "1 ABINGDON SQUARE, MANHATTAN, 10014           3\n",
       "1 ASTOR PLACE, MANHATTAN, 10003               2\n",
       "1 AVENUE, MANHATTAN, 10003                    2\n",
       "1 AVENUE, MANHATTAN, 10009                    2\n",
       "1 BAY CLUB DRIVE, QUEENS, 11360               1\n",
       "1 BAY STREET LANDING, STATEN ISLAND, 10301    1\n",
       "1 BAY STREET, STATEN ISLAND, 10301            5\n",
       "1 BEARD STREET, BROOKLYN, 11231               6\n",
       "1 BEDFORD PARK BOULEVARD, BRONX, 10468        2\n",
       "Name: descriptor, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_311[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75 CHRISTOPHER STREET, MANHATTAN, 10014\n",
       "1             461 37 STREET, BROOKLYN, 11232\n",
       "2             987 2 AVENUE, MANHATTAN, 10022\n",
       "3      925 MANHATTAN AVENUE, BROOKLYN, 11222\n",
       "4    55 CHRISTOPHER STREET, MANHATTAN, 10014\n",
       "5         17 PRINCE STREET, MANHATTAN, 10012\n",
       "6     118 RIVINGTON STREET, MANHATTAN, 10002\n",
       "7        23 WEST 45 STREET, MANHATTAN, 10036\n",
       "8             977 2 AVENUE, MANHATTAN, 10022\n",
       "9       765 CONCOURSE VLG WEST, BRONX, 10451\n",
       "Name: loc, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insp['loc'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25926"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(insp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20590"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_311)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# left join on standardized addresses\n",
    "merged = insp.merge(df_311, left_on='loc', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10176 matches\n"
     ]
    }
   ],
   "source": [
    "merged = merged.loc[:, ['CAMIS', 'descriptor']]\n",
    "merged.columns = ['CAMIS', '311_complaint_count']\n",
    "print '{} matches'.format(sum(map(lambda x: np.isfinite(x), merged['311_complaint_count'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAMIS</th>\n",
       "      <th>311_complaint_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41014823</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40364889</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40571896</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50004740</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41331076</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CAMIS  311_complaint_count\n",
       "0  41014823                  2.0\n",
       "1  40364889                  1.0\n",
       "2  40571896                  NaN\n",
       "3  50004740                  NaN\n",
       "4  41331076                  NaN"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to file\n",
    "merged.to_csv('data/311_complaint.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
