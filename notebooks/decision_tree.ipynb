{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##__Date__:Apr 28\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.metrics import roc_auc_score as rs\n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn import tree\n",
    "import math\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "# read in aggregated data\n",
    "sj = pd.read_csv('spatial_merged_solid.csv')\n",
    "sj = sj[['CAMIS', 'DBA', 'BBL', 'new_grade', 'yelp_rating', 'yelp_categories', 'yelp_review_count', 'stats.checkinsCount', 'stats.tipCount', 'stats.usersCount',\n",
    "       'categories', 'geometry', 'BldgArea', 'BuiltFAR', 'CB2010', 'CT2010', 'HealthArea', 'NumFloors','OfficeArea',\n",
    "        'ResArea', 'RetailArea', 'SHAPE_Area', 'SHAPE_Leng', 'TaxMap', 'Tract2010', 'UnitsRes', 'UnitsTotal', 'YearAlter1', 'YearAlter2', 'YearBuilt']]\n",
    "sj = sj.rename(columns = {'yelp_rating':'yr', 'yelp_categories':'yc', 'yelp_review_count': 'yrc', \\\n",
    "                            'stats.checkinsCount':'fcc', 'stats.tipCount':'ftc', 'stats.usersCount':'fus', 'categories': 'fc'})\n",
    "# consistent format\n",
    "sj.BBL = sj.BBL.apply(int).apply(str)\n",
    "\n",
    "# sj['retail_area_p']: portions of retail area vs. shape area\n",
    "sj['retail_area_p'] = sj.RetailArea / sj.SHAPE_Area\n",
    "# sj['res_u_p']: portions of residential units vs. total units\n",
    "sj['res_u_p'] = sj.UnitsRes / sj.UnitsTotal\n",
    "\n",
    "# load DOF: Condominium Comparable Rental Income as income, real estate rental price indicator\n",
    "# timerange: 2011/2012\n",
    "# notice: lots of nan\n",
    "tm_mn = pd.read_json('https://data.cityofnewyork.us/resource/jmwn-n499.json')\n",
    "tm_bk = pd.read_json('https://data.cityofnewyork.us/resource/dkr7-ts75.json')\n",
    "tm_qn = pd.read_json('https://data.cityofnewyork.us/resource/rrrc-7d8r.json')\n",
    "tm_bx = pd.read_json('https://data.cityofnewyork.us/resource/ieph-a6af.json')\n",
    "tm_si = pd.read_json('https://data.cityofnewyork.us/resource/4rqc-79ny.json')\n",
    "\n",
    "# concatenating\n",
    "def rep_borough(col_list):\n",
    "    return map(lambda x: x.replace('manhattan', '').replace('brooklyn', '').replace('bronx', '')\\\n",
    "    .replace('queens', '').replace('staten_island', ''), col_list)\n",
    "for dt in [tm_mn, tm_bk, tm_bx, tm_qn, tm_si]:\n",
    "    dt.columns = rep_borough(dt.columns.values)\n",
    "tm_m = pd.concat([tm_mn, tm_bk, tm_bx, tm_qn, tm_si])\n",
    "\n",
    "# clean BBL column in tax map as STRING\n",
    "tm_m.rename(columns={'_condominiums_comparable_properties_boro_block_lot' : 'BBL'}, inplace = True)\n",
    "tm_m.BBL = tm_m.BBL.apply(lambda x: str(x.replace('-', '')))\n",
    "tm_m_clean = tm_m[['_condominiums_comparable_properties_expense_per_sqft', '_condominiums_comparable_properties_gross_income_per_sqft',\n",
    "                 '_condominiums_comparable_properties_net_operating_income', 'BBL']]\n",
    "tm_m_clean.columns = ['expense/sqft', 'income/spft', 'opincome', 'BBL']\n",
    "\n",
    "tm_m_clean.head()\n",
    "\n",
    "## Categories feature:\n",
    "- descriptive feature is given by: Yelp(yc), Foursquare(fc), and inspection data itself  \n",
    "- consider approach:   \n",
    "    1. congregate discriptive words from all the 3 sources for each CAMIS  \n",
    "    2. process a long list of words existed in the three columns - return a dictionary(?) of categories  \n",
    "      eg: dic = {'healthy': ['green', 'yogurt', 'salads'], 'american':['hamburgers', 'milkshake', 'fries']}  \n",
    "    3. A boolean matrix M of shape (len(CAMIS), len(dic.keys())  \n",
    "       M[camis, 1] = 1 if any(row['category']) in dic.items()[1][1]  \n",
    "       but: more features to processssssss\n",
    "\n",
    "# merge spatial joined with tax map\n",
    "sj1 = pd.merge(sj, tm_m_clean, on = 'BBL', how = 'left')\n",
    "\n",
    "def alter(row):\n",
    "    '''\n",
    "    return # of times each building is altered\n",
    "    '''\n",
    "    if row['YearAlter2'] != 0.0:\n",
    "        t = 2\n",
    "    elif row['YearAlter1'] != 0.0:\n",
    "        t = 1\n",
    "    else:\n",
    "        t = 0\n",
    "    return t\n",
    "sj1['alter_count'] = sj1.apply(alter, axis = 1)\n",
    "\n",
    "sj2 = sj1[['CAMIS', 'DBA', 'BBL', 'new_grade', 'yr', 'yc', 'yrc', 'fcc', 'ftc','fus', 'fc', \n",
    "           'NumFloors', 'retail_area_p', 'res_u_p', 'alter_count', 'YearBuilt',\n",
    "           'expense/sqft', 'income/spft', 'opincome', 'geometry']]\n",
    "\n",
    "# messing with Y: drop any rows that are missing a new_grade\n",
    "sj2 = sj2.loc[sj2.new_grade.dropna().index, :] \n",
    "sj2['gradeA'] = sj2.apply(lambda x: x['new_grade'] == 'A', axis = 1) #return boolean: true if A\n",
    "\n",
    "#from original inspection data extract 'CUISINE DESCRIPTION' column\n",
    "def sum1(seq):\n",
    "    tot = ' '\n",
    "    for n in seq:\n",
    "        tot = tot + n + ','\n",
    "    return set(tot.split(','))\n",
    "\n",
    "insp_ori = pd.read_csv('DOHMH_New_York_City_Restaurant_Inspection_Results.csv')\n",
    "insp_cat = insp_ori[['CAMIS','CUISINE DESCRIPTION']].groupby('CAMIS', as_index = False).agg({\"CUISINE DESCRIPTION\": sum1})\n",
    "\n",
    "def clean_cuisine_set(x):\n",
    "    y = filter(lambda x: len(x) >0, map(lambda x: x.strip().lower(), x))\n",
    "    return set(y)\n",
    "insp_cat['CUISINE DESCRIPTION'] = insp_cat['CUISINE DESCRIPTION'].apply(clean_cuisine_set)\n",
    "sj3 = pd.merge(sj2, insp_cat, on = 'CAMIS', how = 'left')#add 'CUISINE DESCRIPTION' column to sj3\n",
    "\n",
    "type(sj3['CUISINE DESCRIPTION'][3])\n",
    "\n",
    "# join yelp categories and inspection categories\n",
    "def join_cat_y(x):\n",
    "    if type(x['yc']) != float:\n",
    "        if ',' in x['yc']:\n",
    "            yclist = map(lambda x: x.replace(\"[u'\", '').replace(\"']\", '').replace('u', '').replace('[', '').replace(']', '').\\\n",
    "                         replace(\"'\",'').replace(' ','').replace('caf\\xc3\\x83\\xc2\\xa9/coffee/tea', 'cafe').lower(), x['yc'].split(','))\n",
    "        else:\n",
    "            yclist = map(lambda x: x.replace(\"[u'\", '').replace(\"']\", '').replace('u', '').replace('[', '').replace(']', '').\\\n",
    "                         replace(\"'\",'').replace(' ','').replace('caf\\xc3\\x83\\xc2\\xa9/coffee/tea', 'cafe').lower(), x['yc'].split('u'))\n",
    "        if type(x['CUISINE DESCRIPTION']) == set:\n",
    "            return x['CUISINE DESCRIPTION'].union(set(yclist))\n",
    "        else:\n",
    "            return yclist\n",
    "    else:\n",
    "        return set()\n",
    "# save joined categories    \n",
    "sj3['categories'] = sj3.apply(join_cat_y, axis = 1).apply(list)\n",
    "\n",
    "# join four square categories to 'categories' column\n",
    "\n",
    "def join_cat_f(x):\n",
    "    if type(x['fc']) != float:\n",
    "        if ',' in x['fc']:\n",
    "            fclist = map(lambda x: x.replace(\"[u'\", '').replace(\"']\", '').replace('u', '').replace('[', '').replace(']', '').\\\n",
    "                         replace(\"'\",'').replace(' ','').replace('caf\\xc3\\x83\\xc2\\xa9/coffee/tea', 'cafe').replace('Caf\\xe9', 'cafe')\\\n",
    "                         .lower(), x['fc'].split(','))\n",
    "        else:\n",
    "            fclist = map(lambda x: x.replace(\"[u'\", '').replace(\"']\", '').replace('u', '').replace('[', '').replace(']', '').\\\n",
    "                         replace(\"'\",'').replace(' ','').replace('caf\\xc3\\x83\\xc2\\xa9/coffee/tea', 'cafe').replace('Caf\\xe9', 'cafe')\\\n",
    "                         .lower(), x['fc'].split('u'))\n",
    "        if type(x['CUISINE DESCRIPTION']) == set:\n",
    "            return x['CUISINE DESCRIPTION'].union(set(fclist))\n",
    "        else:\n",
    "            return fclist\n",
    "    else:\n",
    "        return set()\n",
    "\n",
    "sj3['categories'] = sj3.apply(join_cat_f, axis = 1).apply(list)\n",
    "\n",
    "sj3.head()\n",
    "\n",
    "# process all categories\n",
    "des = np.asarray(sj3['categories']).flatten()\n",
    "des_v = []\n",
    "for i in range(len(des)):\n",
    "    for j in range(len(des[i])):\n",
    "        #cleanning on the string:\n",
    "        des[i][j] = des[i][j].replace(' ','')\n",
    "        des[i][j] = des[i][j].replace('.','')\n",
    "        des[i][j] = des[i][j].replace('including','')\n",
    "        des[i][j] = des[i][j].replace('caf\\xc3\\x83\\xc2\\xa9','cafe')\n",
    "        des[i][j] = des[i][j].replace('etc','')\n",
    "        des[i][j] = des[i][j].replace('notapplicable','')\n",
    "        des[i][j] = des[i][j].replace('notlisted','')\n",
    "        des[i][j] = des[i][j].replace('a','').replace('an','').replace('accessories', '').replace('ad','')\n",
    "        \n",
    "        des_v.append(des[i][j].lower())\n",
    "        \n",
    "s = set(des_v)\n",
    "\n",
    "# consider text categories?\n",
    "s #'THE LONG LIST' of descriptive words\n",
    "\n",
    "#### FORGET about categories first\n",
    "## Some decision trees for implementation\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "x = pd.read_csv('feature.csv',index_col = 0)\n",
    "y = pd.read_csv('y.csv', index_col=0, names = ['ifA'])\n",
    "\n",
    "# data\n",
    "sj3['ifA'] = sj3['new_grade'] == 'A' # create boolean list indicating if new_grade == A\n",
    "sj4 = sj3.drop(['yc', 'fc'], axis = 1).replace(np.nan, 0) # ignore categories column first, replace all nan with 0\n",
    "\n",
    "print 'look at features:', sj4.columns[4:17].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtr, xte, ytr, yte = train_test_split(x, y, test_size = .3, random_state = 99)\n",
    "#xtr, xte, ytr, yte = train_test_split(sj4[sj4.columns[4:17]], sj4['ifA'], test_size = 0.3, random_state = 99)\n",
    "\n",
    "# train decision tree\n",
    "rf_ = DTC(max_depth=2) \n",
    "rf_.fit(xtr, ytr)\n",
    "#viz\n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(rf_, out_file=dot_data,  \n",
    "                         feature_names=x.columns.values,  \n",
    "                         class_names=['A', 'not A'],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "img = Image(graph.create_png())\n",
    "\n",
    "with open(\"../viz/dtree2.png\", \"wb\") as png:\n",
    "    png.write(img.data)\n",
    "\n",
    "# train decision tree\n",
    "rf_ = DTC(max_depth=3) \n",
    "rf_.fit(xtr, ytr)\n",
    "#viz\n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(rf_, out_file=dot_data,  \n",
    "                         feature_names=x.columns.values,  \n",
    "                         class_names=['A', 'not A'],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "img = Image(graph.create_png())\n",
    "\n",
    "with open(\"../viz/dtree3.png\", \"wb\") as png:\n",
    "    png.write(img.data)\n",
    "\n",
    "# train decision tree\n",
    "rf_ = DTC(max_depth=4) \n",
    "rf_.fit(xtr, ytr)\n",
    "#viz\n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(rf_, out_file=dot_data,  \n",
    "                         feature_names=x.columns.values,  \n",
    "                         class_names=['A', 'not A'],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "img = Image(graph.create_png())\n",
    "\n",
    "with open(\"../viz/dtree4.png\", \"wb\") as png:\n",
    "    png.write(img.data)\n",
    "\n",
    "# train decision tree\n",
    "rf_ = DTC(max_depth=5) \n",
    "rf_.fit(xtr, ytr)\n",
    "#viz\n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(rf_, out_file=dot_data,  \n",
    "                         feature_names=x.columns.values,  \n",
    "                         class_names=['A', 'not A'],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "img = Image(graph.create_png())\n",
    "\n",
    "with open(\"../viz/dtree5.png\", \"wb\") as png:\n",
    "    png.write(img.data)\n",
    "\n",
    "#performance\n",
    "pred=rf_.predict_proba(xte)\n",
    "pred1 = rf_.predict(xte)\n",
    "def acc(true, pred):\n",
    "    ''' true and pred are labled list\n",
    "    of the same size\n",
    "    return the percentage of rightly-prediced labels'''\n",
    "    return 1.0*(pred==np.asarray(true)).sum()/len(true) \n",
    "print 'decision tree prediction accuracy:', 1.0*(yte.ifA == pred1).sum()/len(yte)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "print 'max_depth 5 decision tree:'\n",
    "print 'roc_auc_score:'\n",
    "print roc_auc_score(yte, pred1)\n",
    "print 'average_precision_score:'\n",
    "print average_precision_score(yte, pred1)\n",
    "\n",
    "(pred1==np.asarray(yte)).sum()\n",
    "\n",
    "1.0*(pred1==np.asarray(yte)).sum()/len(yte) \n",
    "\n",
    "print 'in the whole data set, p(not A) =', 1.0 * sj4[sj4['ifA'] == 0].size/ sj4.size\n",
    "print 'in testing data set, p(not A) = ', 1.0 * yte[yte == 0].size/ yte.size\n",
    "\n",
    "yte"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
