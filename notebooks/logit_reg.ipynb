{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/spatial_merged_solid.csv')\n",
    "topics = pd.read_csv('../data/topic_output.csv')\n",
    "complaint = pd.read_csv('../data/311_complaint.csv')\n",
    "insp = pd.read_csv('../data/clean_bz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge original inspection stuff with main df\n",
    "df = df.merge(insp, on='CAMIS', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge 311 stuff with main df\n",
    "df = df.merge(complaint, on='CAMIS', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "df = df.loc[:, ['CAMIS', # inspection data\n",
    "                'new_grade',\n",
    "                'INSPECTION DATE_y',\n",
    "                'VIOLATION CODE',\n",
    "                'SCORE',\n",
    "                'GRADE_y',\n",
    "                'CD', # pluto data, BBL-level (spatially merged)\n",
    "                'HealthArea',\n",
    "                'SanitDistr',\n",
    "                'AssessTot',\n",
    "                'YearAlter1',\n",
    "                'YearAlter2',\n",
    "                'YearBuilt',\n",
    "                'NumFloors',\n",
    "                'yelp_rating', # yelp data, restaurant-level\n",
    "                'yelp_categories',\n",
    "                'yelp_review_count',\n",
    "                'stats.checkinsCount', # foursquare data, restaurant-level\n",
    "                'stats.tipCount',\n",
    "                'stats.usersCount',\n",
    "                '311_complaint_count', # 311 food complaints, restaurant-level\n",
    "                'goog_lat', # google location\n",
    "                'goog_lng']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rename a couple weird columns post-merge\n",
    "df.columns =   ['CAMIS', # inspection data\n",
    "                'new_grade',\n",
    "                'INSPECTION DATE',\n",
    "                'VIOLATION CODE',\n",
    "                'SCORE',\n",
    "                'GRADE',\n",
    "                'CD', # pluto data, BBL-level (spatially merged)\n",
    "                'HealthArea',\n",
    "                'SanitDistr',\n",
    "                'AssessTot',\n",
    "                'YearAlter1',\n",
    "                'YearAlter2',\n",
    "                'YearBuilt',\n",
    "                'NumFloors',\n",
    "                'yelp_rating', # yelp data, restaurant-level\n",
    "                'yelp_categories',\n",
    "                'yelp_review_count',\n",
    "                'stats.checkinsCount', # foursquare data, restaurant-level\n",
    "                'stats.tipCount',\n",
    "                'stats.usersCount',\n",
    "                '311_complaint_count', # 311 food complaints, restaurant-level\n",
    "                'goog_lat', # google location\n",
    "                'goog_lng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only care about the records with a y-label (either A, B, or C)\n",
    "df = df.loc[map(lambda g: type(g)==str, df.GRADE), :]\n",
    "df = df.loc[df.GRADE.isin(['A', 'B', 'C']), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_cat(cat):\n",
    "    \"\"\"\n",
    "    cleans a single yelp category string\n",
    "    \"\"\"\n",
    "    cat = cat.replace('[', '')\\\n",
    "    .replace(']', '')\\\n",
    "    .replace('u', '')\\\n",
    "    .replace(\"'\", \"\")\\\n",
    "    .replace(\" \", \"\")\n",
    "    \n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_categories(n):\n",
    "    \"\"\"\n",
    "    returns a list of top n yelp categories from observed data\n",
    "    \"\"\"\n",
    "    yelp_cats = list(df.yelp_categories)\n",
    "    yelp_cats = filter(lambda cat: type(cat)==str, yelp_cats)\n",
    "    yelp_cats = ','.join(yelp_cats).split(',')\n",
    "    yelp_cats = map(clean_cat, yelp_cats)\n",
    "    \n",
    "    return map(lambda x: x[0], Counter(yelp_cats).most_common(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coffee',\n",
       " 'pizza',\n",
       " 'sandwiches',\n",
       " 'chinese',\n",
       " 'hotdogs',\n",
       " 'italian',\n",
       " 'breakfast_brnch',\n",
       " 'newamerican',\n",
       " 'bakeries',\n",
       " 'brgers']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing top categories function\n",
    "get_top_categories(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def substring(cat, cats):\n",
    "    \"\"\"\n",
    "    checks if a string contains a substring, with error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(cat in cats)\n",
    "    except TypeError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def category_one_hot(df, n):\n",
    "    \"\"\"\n",
    "    appends 'n' columns to a dataframe\n",
    "    corresponding to yes/no for the 'n' most common yelp categories\n",
    "    \"\"\"\n",
    "    for cat in get_top_categories(n):\n",
    "        col_name = 'is_' + cat\n",
    "        df.loc[:, col_name] = df.apply(lambda row: substring(cat, row['yelp_categories']), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET NUMBER OF FOOD CATEGORIES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SET NUMBER OF FOOD CATEGORIES HERE\n",
    "food_num = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAMIS</th>\n",
       "      <th>new_grade</th>\n",
       "      <th>INSPECTION DATE</th>\n",
       "      <th>VIOLATION CODE</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>CD</th>\n",
       "      <th>HealthArea</th>\n",
       "      <th>SanitDistr</th>\n",
       "      <th>AssessTot</th>\n",
       "      <th>...</th>\n",
       "      <th>is_tradamerican</th>\n",
       "      <th>is_bars</th>\n",
       "      <th>is_mexican</th>\n",
       "      <th>is_donts</th>\n",
       "      <th>is_cafes</th>\n",
       "      <th>is_salad</th>\n",
       "      <th>is_japanese</th>\n",
       "      <th>is_desserts</th>\n",
       "      <th>is_seafood</th>\n",
       "      <th>is_icecream</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>50060711</td>\n",
       "      <td>A</td>\n",
       "      <td>03/22/2017</td>\n",
       "      <td>10H</td>\n",
       "      <td>7.0</td>\n",
       "      <td>A</td>\n",
       "      <td>107.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2049750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>50060463</td>\n",
       "      <td>A</td>\n",
       "      <td>03/02/2017</td>\n",
       "      <td>06F</td>\n",
       "      <td>13.0</td>\n",
       "      <td>A</td>\n",
       "      <td>310.0</td>\n",
       "      <td>7820.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>141750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>50060418</td>\n",
       "      <td>A</td>\n",
       "      <td>03/22/2017</td>\n",
       "      <td>06C</td>\n",
       "      <td>9.0</td>\n",
       "      <td>A</td>\n",
       "      <td>106.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15238350.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>50060396</td>\n",
       "      <td>A</td>\n",
       "      <td>03/06/2017</td>\n",
       "      <td>10F</td>\n",
       "      <td>7.0</td>\n",
       "      <td>A</td>\n",
       "      <td>414.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>329850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>50060377</td>\n",
       "      <td>A</td>\n",
       "      <td>03/23/2017</td>\n",
       "      <td>04L</td>\n",
       "      <td>13.0</td>\n",
       "      <td>A</td>\n",
       "      <td>401.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27216.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CAMIS new_grade INSPECTION DATE VIOLATION CODE  SCORE GRADE     CD  \\\n",
       "225  50060711         A      03/22/2017            10H    7.0     A  107.0   \n",
       "259  50060463         A      03/02/2017            06F   13.0     A  310.0   \n",
       "266  50060418         A      03/22/2017            06C    9.0     A  106.0   \n",
       "270  50060396         A      03/06/2017            10F    7.0     A  414.0   \n",
       "276  50060377         A      03/23/2017            04L   13.0     A  401.0   \n",
       "\n",
       "     HealthArea  SanitDistr   AssessTot     ...       is_tradamerican  \\\n",
       "225      3500.0         7.0   2049750.0     ...                     0   \n",
       "259      7820.0        10.0    141750.0     ...                     0   \n",
       "266      5000.0         6.0  15238350.0     ...                     0   \n",
       "270      3700.0        14.0    329850.0     ...                     0   \n",
       "276       400.0         1.0     27216.0     ...                     0   \n",
       "\n",
       "     is_bars  is_mexican  is_donts  is_cafes is_salad  is_japanese  \\\n",
       "225        0           0         0         0        0            0   \n",
       "259        0           0         0         0        0            0   \n",
       "266        0           0         0         0        0            0   \n",
       "270        0           0         0         0        0            0   \n",
       "276        0           0         0         0        0            0   \n",
       "\n",
       "     is_desserts  is_seafood  is_icecream  \n",
       "225            0           0            0  \n",
       "259            0           0            0  \n",
       "266            0           0            0  \n",
       "270            0           0            0  \n",
       "276            0           0            0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append cuisine category one-hots to dataframe\n",
    "df = category_one_hot(df, food_num)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_y(row):\n",
    "    \"\"\"\n",
    "    output label: 1 for bad inspection, 0 for normal\n",
    "    \"\"\"\n",
    "    if row['GRADE'] in ['B', 'C']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the final label variable\n",
    "df.loc[:, 'failed'] = df.apply(create_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAMIS</th>\n",
       "      <th>new_grade</th>\n",
       "      <th>INSPECTION DATE</th>\n",
       "      <th>VIOLATION CODE</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>CD</th>\n",
       "      <th>HealthArea</th>\n",
       "      <th>SanitDistr</th>\n",
       "      <th>AssessTot</th>\n",
       "      <th>...</th>\n",
       "      <th>is_tradamerican</th>\n",
       "      <th>is_bars</th>\n",
       "      <th>is_mexican</th>\n",
       "      <th>is_donts</th>\n",
       "      <th>is_cafes</th>\n",
       "      <th>is_salad</th>\n",
       "      <th>is_japanese</th>\n",
       "      <th>is_desserts</th>\n",
       "      <th>is_seafood</th>\n",
       "      <th>is_icecream</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8078</td>\n",
       "      <td>7872</td>\n",
       "      <td>8078</td>\n",
       "      <td>7946</td>\n",
       "      <td>8078</td>\n",
       "      <td>8078</td>\n",
       "      <td>8078</td>\n",
       "      <td>8078</td>\n",
       "      <td>8068</td>\n",
       "      <td>8078</td>\n",
       "      <td>...</td>\n",
       "      <td>8078</td>\n",
       "      <td>8078</td>\n",
       "      <td>8078</td>\n",
       "      <td>8078</td>\n",
       "      <td>8078</td>\n",
       "      <td>8078</td>\n",
       "      <td>8078</td>\n",
       "      <td>8078</td>\n",
       "      <td>8078</td>\n",
       "      <td>8078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>846</td>\n",
       "      <td>813</td>\n",
       "      <td>846</td>\n",
       "      <td>843</td>\n",
       "      <td>846</td>\n",
       "      <td>846</td>\n",
       "      <td>846</td>\n",
       "      <td>846</td>\n",
       "      <td>845</td>\n",
       "      <td>846</td>\n",
       "      <td>...</td>\n",
       "      <td>846</td>\n",
       "      <td>846</td>\n",
       "      <td>846</td>\n",
       "      <td>846</td>\n",
       "      <td>846</td>\n",
       "      <td>846</td>\n",
       "      <td>846</td>\n",
       "      <td>846</td>\n",
       "      <td>846</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CAMIS  new_grade  INSPECTION DATE  VIOLATION CODE  SCORE  GRADE    CD  \\\n",
       "failed                                                                          \n",
       "0        8078       7872             8078            7946   8078   8078  8078   \n",
       "1         846        813              846             843    846    846   846   \n",
       "\n",
       "        HealthArea  SanitDistr  AssessTot     ...       is_tradamerican  \\\n",
       "failed                                        ...                         \n",
       "0             8078        8068       8078     ...                  8078   \n",
       "1              846         845        846     ...                   846   \n",
       "\n",
       "        is_bars  is_mexican  is_donts  is_cafes  is_salad  is_japanese  \\\n",
       "failed                                                                   \n",
       "0          8078        8078      8078      8078      8078         8078   \n",
       "1           846         846       846       846       846          846   \n",
       "\n",
       "        is_desserts  is_seafood  is_icecream  \n",
       "failed                                        \n",
       "0              8078        8078         8078  \n",
       "1               846         846          846  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('failed').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# years since renovation\n",
    "def get_yrs_since_reno(row):\n",
    "    last_reno = max(row['YearAlter1'], row['YearAlter2'])\n",
    "    if last_reno == 0:\n",
    "        return 2017 - row['YearBuilt']\n",
    "    else:\n",
    "        return 2017 - last_reno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# years since renovation\n",
    "df.loc[:, 'yrs_since_reno'] = df.apply(get_yrs_since_reno, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# building age\n",
    "df.loc[:, 'bldg_age'] = df.apply(lambda row: 2017 - row['YearBuilt'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selection here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerics = [u'AssessTot', u'NumFloors', u'yelp_rating', u'yelp_review_count',\n",
    "       u'stats.checkinsCount', u'stats.tipCount', u'stats.usersCount',\n",
    "       u'311_complaint_count', u'yrs_since_reno', u'bldg_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#categoricals = [u'CD', u'HealthArea', u'SanitDistr'] + \\\n",
    "#    map(lambda cuisine: 'is_' + cuisine, get_top_categories(food_num))\n",
    "    \n",
    "categoricals = ['CD'] + map(lambda cuisine: 'is_' + cuisine, get_top_categories(food_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize numeric columns\n",
    "for col in numerics:\n",
    "    vect = df.loc[:, col]\n",
    "    mean = np.nanmean(vect)\n",
    "    std = np.nanstd(vect)\n",
    "    df.loc[:, col] = (vect - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these columns look like numericals, but are actually categorical\n",
    "# convert to strings (with a prefix), so that scikitlearn algos can treat them as categorical\n",
    "def stringize(num, prefix):\n",
    "    if math.isnan(num):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return prefix + '_' + str(int(num))\n",
    "\n",
    "for col in [u'CD', u'HealthArea', u'SanitDistr']:\n",
    "    df.loc[:, col] = map(lambda val: stringize(val, col), df.loc[:, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill missing FS, Yelp, and 311 data with zeroes\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create X and y from all selected features\n",
    "X = pd.concat([df.loc[:, numerics], df.loc[:, categoricals]], axis=1)\n",
    "y = df.failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one-hot encoding for the three high-cardinality columns\n",
    "if 'CD' in X.columns:\n",
    "    X = pd.concat([X, pd.get_dummies(X.loc[:, 'CD'])], axis=1)\n",
    "    X.drop('CD', axis=1, inplace=True)\n",
    "\n",
    "if 'HealthArea' in X.columns:\n",
    "    X = pd.concat([X, pd.get_dummies(X.loc[:, 'HealthArea'])], axis=1)\n",
    "    X.drop('HealthArea', axis=1, inplace=True)\n",
    "\n",
    "if 'SanitDistr' in X.columns:\n",
    "    X = pd.concat([X, pd.get_dummies(X.loc[:, 'SanitDistr'])], axis=1)\n",
    "    X.drop('SanitDistr', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_csv('feature.csv')\n",
    "df['SCORE'].to_csv('yscore.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP = sum((y_pred==1)&(y_test==1))\n",
    "FP = sum((y_pred==1)&(y_test==0))\n",
    "FN = sum((y_pred==0)&(y_test==1))\n",
    "TN = sum((y_pred==0)&(y_test==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2758 predicted failures\n"
     ]
    }
   ],
   "source": [
    "print '{} predicted failures'.format(sum(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB:\n",
      "Precision = 9.61%\n",
      "Accuracy = 14.80%\n",
      "Recall = 94.31%\n"
     ]
    }
   ],
   "source": [
    "# calculate precision, accuracy, and recall\n",
    "Acc = 100.0 * (TP + TN) / (TP + TN + FP + FN) # correct predictions / all records\n",
    "Rec = 100.0 * TP / (TP + FN) # correctly predicted positives / all positive records\n",
    "Prec = 100.0 * TP / (TP + FP) # correctly predicted positives / all predicted positives\n",
    "\n",
    "print('GaussianNB:')\n",
    "print('Precision = %.2f%%\\nAccuracy = %.2f%%\\nRecall = %.2f%%'%(Prec,Acc,Rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(C=1e6)\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP = sum((y_pred==1)&(y_test==1))\n",
    "FP = sum((y_pred==1)&(y_test==0))\n",
    "FN = sum((y_pred==0)&(y_test==1))\n",
    "TN = sum((y_pred==0)&(y_test==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09449740759324302"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(sum(y_train)) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 predicted failures\n"
     ]
    }
   ],
   "source": [
    "print '{} predicted failures'.format(sum(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Precision = 50.00%\n",
      "Accuracy = 90.46%\n",
      "Recall = 0.36%\n"
     ]
    }
   ],
   "source": [
    "# calculate precision, accuracy, and recall\n",
    "Acc = 100.0 * (TP + TN) / (TP + TN + FP + FN)\n",
    "Rec = 100.0 * TP / (TP + FN)\n",
    "Prec = 100.0 * TP / (TP + FP)\n",
    "\n",
    "print('Logistic Regression:')\n",
    "print('Precision = %.2f%%\\nAccuracy = %.2f%%\\nRecall = %.2f%%'%(Prec,Acc,Rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_mod = svm.SVC() \n",
    "svm_mod.fit(X_train, y_train)\n",
    "y_pred = svm_mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP = sum((y_pred==1)&(y_test==1))\n",
    "FP = sum((y_pred==1)&(y_test==0))\n",
    "FN = sum((y_pred==0)&(y_test==1))\n",
    "TN = sum((y_pred==0)&(y_test==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 predicted failures\n"
     ]
    }
   ],
   "source": [
    "print '{} predicted failures'.format(sum(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-520923a1a5cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mAcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mRec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mPrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic Regression:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# calculate precision, accuracy, and recall\n",
    "Acc = 100.0 * (TP + TN) / (TP + TN + FP + FN)\n",
    "Rec = 100.0 * TP / (TP + FN)\n",
    "Prec = 100.0 * TP / (TP + FP)\n",
    "\n",
    "print('Logistic Regression:')\n",
    "print('Precision = %.2f%%\\nAccuracy = %.2f%%\\nRecall = %.2f%%'%(Prec,Acc,Rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
